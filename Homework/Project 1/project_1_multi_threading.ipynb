{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This project involves collecting and analyzing data related to adoptable dogs from Petfinder.com, a reputable online database of animals who need homes. The data was collected on November 1st, 2024 using web scraping techniques to gather information on dogs available for adoption in a specific region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source of the Data\n",
    "\n",
    "- Website: Petfinder.com\n",
    "- Focus: Adoptable dogs listed on the website\n",
    "- Location Filter: Data was restricted to dogs available in Georgia to maintain a manageable dataset and focus on a specific geographical area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collected\n",
    "\n",
    "The following information was collected for each dog:\n",
    "- Pet ID: A unique identifier assigned by Petfinder\n",
    "- Name: The name given to the dog by the shelter or rescue organization\n",
    "- Primary Breed: The primary breed of the dog\n",
    "- Secondary Breed: The secondary breed of the dog\n",
    "- Mixed Breed: An indicator (e.g, Yes or No) showing whether the dog is of mixed breed\n",
    "- Age: Categorized as Baby, Young, Adult, or Senior\n",
    "- Sex: Male or Female\n",
    "- Size: The size category of the dog, such as Small, Medium, Large, or Extra Large\n",
    "- Primary Colour: The predominant color of the dog's coat\n",
    "- Secondary Colour: The secondary color present in the dog's coat, if any\n",
    "- Coat Length: The length of the dog's coat, categorized as Hairless, Short, Medium, or Long\n",
    "- Shelter Name: The name of the shelter or rescue organization currently caring for the dog\n",
    "- Zip Code: The postal code of the shelter's location\n",
    "- Number of Photos: The number of photos available for the dog in its listing\n",
    "- Children: An indicator of whether the dog is suitable for homes with children\n",
    "- Cats: An indicator of whether the dog gets along well with cats\n",
    "- Other Dogs: An indicator of whether the dog is friendly towards other dogs\n",
    "- Characteristics: Descriptive traits and personality attributes of the dog\n",
    "- House Trained: An indicator of whether the dog is trained to eliminate outside or in designated areas\n",
    "- Health: Information regarding the dog's health status, including vaccinations, spay/neuter status, and any special needs\n",
    "- Adoption Fee: The cost associated with adopting the dog, when available\n",
    "\n",
    "To begin, I am collecting all available data for each dog and will refine the scope during the analysis phase once I determine the specific questions I want to address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decisions to Restrict Data Collection\n",
    "\n",
    "- Respecting Terms of Service: Ensured that the scraping process complied with Petfinder's terms of use and robots.txt file\n",
    "- Error Handling: Implemented exception handling to manage unexpected issues without causing undue strain on the website\n",
    "- Duplicate Avoidance: Implemented checks to prevent collecting duplicate entries, ensuring each pet is uniquely represented\n",
    "- **Data Cleaning and Validation: Please see \"data_cleaning.ipynb\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Needed Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, InvalidSelectorException\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor, wait\n",
    "import threading\n",
    "import traceback\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thread_name_fn():\n",
    "    thread_name_raw = threading.current_thread().name\n",
    "    thread_name = re.sub(r\"ThreadPoolExecutor-\\d+_(\\d+)\", r\"ThreadPoolExecutor-0_\\1\", thread_name_raw)\n",
    "    return thread_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_driver_fn(options):\n",
    "    global drivers_dict\n",
    "    thread_name = thread_name_fn()\n",
    "    if thread_name not in drivers_dict:\n",
    "        service = Service(executable_path=ChromeDriverManager().install())\n",
    "        drivers_dict[thread_name] = webdriver.Chrome(service=service, options=options)\n",
    "    driver = drivers_dict[thread_name]\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navigate_to_page(driver, page_number):\n",
    "    current_page = 1\n",
    "    while current_page < page_number:\n",
    "        try:\n",
    "            # Waiting for the \"Next\" button to be clickable\n",
    "            next_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, '//button[span[text()=\"Next\"]]'))\n",
    "            )\n",
    "            # Scrolling to the \"Next\" button and clicking it\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "            next_button.click()\n",
    "            current_page += 1\n",
    "            # Waiting for the new page of results to load\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '//a[@class=\"petCard-link\"]'))\n",
    "            )\n",
    "            # Adding a short delay to ensure the page loads \n",
    "            time.sleep(1)  \n",
    "        except Exception as e:\n",
    "            print(f\"Error navigating to page {page_number}: {e}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_pages(driver):\n",
    "    try:\n",
    "        # Waiting for the custom element to be present\n",
    "        total_pages_element = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.XPATH, '//*[@id=\"page-select_List_Box_Btn\"]')\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Getting the number of total pages and extracting the digits\n",
    "        total_pages_text = total_pages_element.text.strip()\n",
    "        total_page_result = re.search(r'/(\\d+)', total_pages_text)\n",
    "        total_page = total_page_result.group(1)\n",
    "        \n",
    "        # Converting from a string to an integer \n",
    "        total_page_num = int(total_page)\n",
    "        return total_page_num\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting total pages: {e}\")\n",
    "        if 'driver' in locals():\n",
    "            driver.save_screenshot(f\"get_total_pages_error_{int(time.time())}.png\")\n",
    "        traceback.print_exc()\n",
    "        return 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to navigate to the desired page \n",
    "def search_dogs(URL, location, driver):\n",
    "    try:\n",
    "        # Navigating to the website\n",
    "        driver.get(URL)\n",
    "\n",
    "        # Giving the website some time to load (to ensure \"Dogs\" will set in the animal type search bar) \n",
    "        time.sleep(2)\n",
    "\n",
    "        # Waiting for animal type search bar to load and be ready for interaction \n",
    "        form_type = WebDriverWait(driver, 40).until(\n",
    "            EC.element_to_be_clickable((By.ID, 'simpleSearchAnimalType'))\n",
    "        )\n",
    "        form_type.clear()\n",
    "        form_type.send_keys(\"Dogs\")\n",
    "\n",
    "        # Finding the location search bar element and ensure it is ready for interaction \n",
    "        form_location = WebDriverWait(driver, 40).until(\n",
    "            EC.element_to_be_clickable((By.ID, 'simpleSearchLocation'))\n",
    "        )\n",
    "        form_location.clear()\n",
    "        form_location.send_keys(location)\n",
    "        \n",
    "        # Allowing the location to be set before clicking the search button\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Clicking the search button to submit the form\n",
    "        search_button = WebDriverWait(driver, 40).until(\n",
    "            EC.element_to_be_clickable((By.ID, 'petSearchBarSearchButton'))\n",
    "        )\n",
    "        # search_button = driver.find_element(By.ID, 'petSearchBarSearchButton')\n",
    "        search_button.click()\n",
    "\n",
    "        # Wait for the results to load\n",
    "        WebDriverWait(driver, 40).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//a[@class=\"petCard-link\"]'))\n",
    "        )\n",
    "        search_results_url = driver.current_url\n",
    "        print(search_results_url)\n",
    "        return search_results_url\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while searching for adoptable dogs: {str(e)}\")\n",
    "        print(\"driver.current_url\", driver.current_url)\n",
    "        if 'driver' in locals():\n",
    "            driver.save_screenshot(f\"search_dogs_error_{int(time.time())}.png\")\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(driver, page_number):\n",
    "    try:\n",
    "        # Creating a list to store dog data \n",
    "        dog_data_list = []\n",
    "        # Creating a list to track missing data for each dog \n",
    "        incomplete_data = []\n",
    "        # Creating a set to keep track of pet IDs \n",
    "        processed_pet_ids = set()  \n",
    "\n",
    "        \n",
    "        # Waiting for the dog cards to be clickable\n",
    "        WebDriverWait(driver, 40).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, '//a[@class=\"petCard-link\"]'))\n",
    "        )\n",
    "        dog_cards = driver.find_elements(By.XPATH, '//a[@class=\"petCard-link\"]')\n",
    "        print(f\"Found {len(dog_cards)} dog cards on page {page_number}.\")\n",
    "\n",
    "        # Extracting the hrefs from the dog cards\n",
    "        dog_links = [card.get_attribute('href') for card in dog_cards]\n",
    "\n",
    "        # Looping through each dog card on the page\n",
    "        for i, link in enumerate(dog_links):\n",
    "            # Creating dictionary to store data for each dog \n",
    "            dog_info_dict = {}\n",
    "            try:\n",
    "                print(f\"Processing dog {i + 1} on page {page_number}.\")\n",
    "\n",
    "                # Navigating to the dog detail page\n",
    "                driver.get(link)\n",
    "\n",
    "                # Waiting for the dog's detail page to load\n",
    "                WebDriverWait(driver, 40).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, '//pf-ad[contains(@id, \"PetDetail\")]'))\n",
    "                )\n",
    "\n",
    "                # Finding the <pf-ad> element that contains the dogs details \n",
    "                pf_ad = driver.find_element(By.XPATH, '//pf-ad[contains(@id, \"PetDetail\")]')\n",
    "                targeting_data = pf_ad.get_attribute(\"targeting\")\n",
    "                dog_info = json.loads(targeting_data)\n",
    "\n",
    "                # Getting the pet ID\n",
    "                pet_id = dog_info.get('Pet_ID', 'N/A')\n",
    "                if pet_id == 'N/A':\n",
    "                    print(f\"Pet ID not found for dog {i + 1} on page. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Checking if pet ID is already processed\n",
    "                if pet_id in processed_pet_ids:\n",
    "                    print(f\"Pet ID {pet_id} already processed. Skipping dog {i + 1} on page {page_number}.\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "                # Defining the fields I want and what I want to call the column names\n",
    "                fields = [\n",
    "                    ('pet_id', 'Pet_ID'),\n",
    "                    ('pet_name', 'Pet_Name'), \n",
    "                    ('primary_breed', 'Primary_Breed'), \n",
    "                    ('secondary_breed', 'Secondary_Breed'),\n",
    "                    ('mixed_breed', 'Mixed_Breed'), \n",
    "                    ('age', 'Age'), \n",
    "                    ('gender', 'Gender'), \n",
    "                    ('size', 'Size'), \n",
    "                    ('primary_colour', 'Primary_color'), \n",
    "                    ('secondary_colour', 'Secondary_color'), \n",
    "                    ('coat_length', 'Coat_length'), \n",
    "                    ('shelter_name', 'Shelter_Name'), \n",
    "                    ('shelter_id', 'Shelter_ID'), \n",
    "                    ('zip_code', 'Zip_Code'), \n",
    "                    ('num_photos', 'Number_of_photos_in_profile'), \n",
    "                    ('children', 'Good_with_children'), \n",
    "                    ('cats', 'Good_with_cats'), \n",
    "                    ('other_dogs', 'Good_with_dogs'), \n",
    "                    ('other_animals', 'Good_with_other_animals'), \n",
    "                    ('fee_waived', 'Adoption_fee_waived')\n",
    "                ]\n",
    "\n",
    "                # Iterating through each field\n",
    "                for key, dog_info_key in fields:\n",
    "                    try:\n",
    "                        dog_info_dict[key] = dog_info.get(dog_info_key, 'N/A')\n",
    "                        if dog_info_dict[key] == 'N/A':\n",
    "                            incomplete_data.append({'pet_id': pet_id, 'field': key, 'error': 'Data not found in JSON'})\n",
    "                    except Exception as e:\n",
    "                        dog_info_dict[key] = 'N/A'\n",
    "                        incomplete_data.append({'pet_id': pet_id, 'field': key, 'error': str(e)})\n",
    "\n",
    "                # Handling fields that are not in the <pf_ad> tag \n",
    "                try:\n",
    "                    pet_location = driver.find_element('xpath', '//span[@data-test=\"Pet_Location\"]').text\n",
    "                    dog_info_dict['pet_location'] = pet_location\n",
    "                except:\n",
    "                    dog_info_dict['pet_location'] = 'N/A'\n",
    "                    incomplete_data.append({'pet_id': pet_id, 'field': 'pet_location', 'error': 'Not found on page'})\n",
    "\n",
    "                try:\n",
    "                    characteristics = driver.find_element('xpath', '//dt[contains(text(), \"Characteristics\")]/following-sibling::dd').text\n",
    "                    dog_info_dict['characteristics'] = characteristics\n",
    "                except:\n",
    "                    dog_info_dict['characteristics'] = 'N/A'\n",
    "                    incomplete_data.append({'pet_id': pet_id, 'field': 'characteristics', 'error': 'Not found on page'})\n",
    "\n",
    "                try:\n",
    "                    house_trained = driver.find_element('xpath', '//dt[contains(text(), \"House-trained\")]/following-sibling::dd').text\n",
    "                    dog_info_dict['house_trained'] = house_trained\n",
    "                except:\n",
    "                    dog_info_dict['house_trained'] = 'N/A'\n",
    "                    incomplete_data.append({'pet_id': pet_id, 'field': 'house_trained', 'error': 'Not found on page'})\n",
    "\n",
    "                try:\n",
    "                    health = driver.find_element('xpath', '//dt[contains(text(), \"Health\")]/following-sibling::dd').text\n",
    "                    dog_info_dict['health'] = health\n",
    "                except:\n",
    "                    dog_info_dict['health'] = 'N/A'\n",
    "                    incomplete_data.append({'pet_id': pet_id, 'field': 'health', 'error': 'Not found on page'})\n",
    "\n",
    "                try:\n",
    "                    # First, check if the adoption fee is in the about section\n",
    "                    adoption_fee_element = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located(\n",
    "                            (By.XPATH, \"//dt[contains(text(), 'Adoption fee')]/following-sibling::dd\")\n",
    "                        )\n",
    "                    )\n",
    "                    adoption_fee = adoption_fee_element.text.strip()\n",
    "                except (NoSuchElementException, TimeoutException, InvalidSelectorException) as e:\n",
    "                    # If not in the about section, log the error and check the pet story section\n",
    "                    incomplete_data.append({'pet_id': pet_id, 'field': 'adoption_fee_about_section', 'error': str(e)})\n",
    "                    try:\n",
    "                        # Wait for the pet story section to be present\n",
    "                        pet_story_element = WebDriverWait(driver, 10).until(\n",
    "                            EC.presence_of_element_located((By.XPATH, '//div[@data-test=\"Pet_Story_Section\"]'))\n",
    "                        )\n",
    "                        pet_story_text = pet_story_element.text\n",
    "                        # Use regex to search for the adoption fee\n",
    "                        adoption_fee_search = re.search(r'Adoption fee[:\\s$]*([\\d.,]+)', pet_story_text, re.IGNORECASE)\n",
    "                        if adoption_fee_search:\n",
    "                            adoption_fee = adoption_fee_search.group(1)\n",
    "                        else:\n",
    "                            adoption_fee = 'N/A'\n",
    "                            incomplete_data.append({'pet_id': pet_id, 'field': 'adoption_fee_pet_story', 'error': 'Not found in pet story text'})\n",
    "                    except (NoSuchElementException, TimeoutException) as e:\n",
    "                        # Log failure in pet story section\n",
    "                        adoption_fee = 'N/A'\n",
    "                        incomplete_data.append({'pet_id': pet_id, 'field': 'adoption_fee_pet_story_section', 'error': str(e)})\n",
    "                else:\n",
    "                    # If adoption fee was found in the about section, proceed\n",
    "                    adoption_fee = adoption_fee.strip()\n",
    "                        \n",
    "                # Appending a dictionary of all the values for the given dog to the dog_data_list \n",
    "                dog_data_list.append(dog_info_dict)\n",
    "                print(f\"Collected data for pet_name {dog_info_dict.get('pet_name', 'N/A')} with pet_id {dog_info_dict.get('pet_id', 'N/A')}\")\n",
    "\n",
    "                # Adding the pet ID to the set of processed IDs\n",
    "                processed_pet_ids.add(pet_id)\n",
    "\n",
    "                # Navigating back to the results page\n",
    "                driver.back()\n",
    "\n",
    "                # Waiting for dog cards to reload\n",
    "                WebDriverWait(driver, 40).until(\n",
    "                    EC.presence_of_all_elements_located((By.XPATH, '//a[@class=\"petCard-link\"]'))\n",
    "                )\n",
    "\n",
    "            # Error message if cannot process dog on the given page but continuing with the next dog \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing dog {i + 1} on page: {page_number} {e}\")\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "\n",
    "        # # Printing incomplete data information\n",
    "        # if incomplete_data:\n",
    "        #     print(\"Summary of incomplete data fields:\")\n",
    "        #     for entry in incomplete_data:\n",
    "        #         print(entry)\n",
    "\n",
    "        # Returing dog data and incomplete data \n",
    "        return {'dog_data': dog_data_list, 'incomplete_data': incomplete_data}\n",
    "\n",
    "\n",
    "    finally:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_scraping(options, search_results_url, page_number):\n",
    "    try:\n",
    "        service = Service(executable_path=ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "        # Modifying the URL to include the page number\n",
    "        if 'page=' in search_results_url:\n",
    "            page_url = re.sub(r'page=\\d+', f'page={page_number}', search_results_url)\n",
    "        else:\n",
    "            delimiter = '&' if '?' in search_results_url else '?'\n",
    "            page_url = f\"{search_results_url}{delimiter}page={page_number}\"\n",
    "\n",
    "        driver.get(page_url)\n",
    "\n",
    "        # Waiting for the page to load\n",
    "        WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//a[@class=\"petCard-link\"]'))\n",
    "        )\n",
    "\n",
    "        # Extracting data from the page\n",
    "        dog_data = get_info(driver, page_number)\n",
    "        return dog_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in thread {threading.current_thread().name}: {e}\")\n",
    "        if 'driver' in locals():\n",
    "            driver.save_screenshot(f\"custom_scraping_error_{int(time.time())}.png\")\n",
    "        traceback.print_exc()\n",
    "        return []\n",
    "    finally:\n",
    "        if 'driver' in locals():\n",
    "            driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    location = \"Georgia\"\n",
    "    URL = \"https://www.petfinder.com\"\n",
    "    options = Options()\n",
    "    options.add_argument(\"headless\")\n",
    "\n",
    "\n",
    "    # Initializing driver to perform the search and get the search results URL\n",
    "    service = Service(executable_path=ChromeDriverManager().install())\n",
    "    temp_driver = webdriver.Chrome(service=service, options=options)\n",
    "    search_results_url = search_dogs(URL, location, temp_driver)\n",
    "\n",
    "    if not search_results_url:\n",
    "        print(\"Failed to get search results URL.\")\n",
    "        return\n",
    "\n",
    "    # Getting total pages\n",
    "    total_pages = get_total_pages(temp_driver)\n",
    "    temp_driver.quit()\n",
    "\n",
    "    print(f\"Total pages to scrape: {total_pages}\")\n",
    "\n",
    "    # Generating a list of page numbers\n",
    "    page_numbers = list(range(1, total_pages + 1))\n",
    "\n",
    "    # Limiting the number of threads\n",
    "    max_workers = min(5, total_pages)\n",
    "\n",
    "    # Initializing lists to collect all data\n",
    "    all_dog_data = []\n",
    "    all_incomplete_data = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [\n",
    "            executor.submit(custom_scraping, options, search_results_url, page_number)\n",
    "            for page_number in page_numbers\n",
    "        ]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                data = future.result()\n",
    "                all_dog_data.extend(data['dog_data'])\n",
    "                all_incomplete_data.extend(data['incomplete_data'])\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                traceback.print_exc()\n",
    "\n",
    "    print(f\"Total dogs collected: {len(all_dog_data)}\")\n",
    "    print(f\"Total incomplete data entries: {len(all_incomplete_data)}\")   \n",
    "\n",
    "    # Saving dog data to a csv \n",
    "    if all_dog_data:\n",
    "        df_dog_data = pd.DataFrame(all_dog_data)\n",
    "        df_dog_data.to_csv('georgia_dogs.csv', index=False)\n",
    "        print(\"Data saved to georgia_dogs.csv\")\n",
    "    else:\n",
    "        print(\"No data collected.\")\n",
    "\n",
    "    # Saving incomplete dog data to a csv \n",
    "    if all_incomplete_data:\n",
    "        df_incomplete = pd.DataFrame(all_incomplete_data)\n",
    "        df_incomplete.to_csv('incomplete_data.csv', index=False)\n",
    "        print(\"Incomplete data saved to incomplete_data.csv\")\n",
    "    else:\n",
    "        print(\"No incomplete data collected.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
