{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> Lecture 17: Neural Networks and Tensor Flow </span>\n",
    "\n",
    "<font size = \"5\">\n",
    "\n",
    "In this class we will talk about how to set up <br>\n",
    "a neural network classifier using Tensor Flow\n",
    "\n",
    "For an introduction\n",
    "\n",
    "https://www.youtube.com/watch?v=i8NETqtGHms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> I. Setup Working Environment </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font size = \"5\">\n",
    "\n",
    "We will be using a new library called \"Tensor Flow\" that is used <br>\n",
    "to create neural network architectures\n",
    "\n",
    "In Windows (Anaconda Prompt) or Mac (Terminal) type:\n",
    "\n",
    "``` conda install tensorflow ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the package for the University of California Irvine API\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# Import SK-Learn library for machine learning functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import get_scorer_names\n",
    "\n",
    "\n",
    "# Import standard data analysis packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Import tensor flow packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import standard data analysis packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> II. Data </span>\n",
    "\n",
    "<font size = \"5\">\n",
    "\n",
    "Online Shoppers Purchasing Intention Dataset (OSHPID)\n",
    "\n",
    "- This dataset contains information about user sessions\n",
    "- It contains features data about user behavior \n",
    "while <br> navigating website\n",
    "- The goal is to predict whether the customer will purchase or not\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/468/online+shoppers+purchasing+intention+dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch online data from the UC Irvine Machine Learning Repository API\n",
    "online_shopping= fetch_ucirepo(id=468) \n",
    "\n",
    "# Extract\n",
    "X = online_shopping.data.features\n",
    "# Drop columns that contain non-numeric values\n",
    "X = X.drop(columns = [\"Month\",\"VisitorType\"])\n",
    "\n",
    "# Extract label data\n",
    "y = online_shopping.data.targets[\"Revenue\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Weekend'] = X['Weekend'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>Weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12325</th>\n",
       "      <td>3</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53</td>\n",
       "      <td>1783.791667</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.029031</td>\n",
       "      <td>12.241717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12326</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>465.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12327</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>184.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12328</th>\n",
       "      <td>4</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12329</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12330 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Administrative  Administrative_Duration  Informational  \\\n",
       "0                   0                      0.0              0   \n",
       "1                   0                      0.0              0   \n",
       "2                   0                      0.0              0   \n",
       "3                   0                      0.0              0   \n",
       "4                   0                      0.0              0   \n",
       "...               ...                      ...            ...   \n",
       "12325               3                    145.0              0   \n",
       "12326               0                      0.0              0   \n",
       "12327               0                      0.0              0   \n",
       "12328               4                     75.0              0   \n",
       "12329               0                      0.0              0   \n",
       "\n",
       "       Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                         0.0               1                 0.000000   \n",
       "1                         0.0               2                64.000000   \n",
       "2                         0.0               1                 0.000000   \n",
       "3                         0.0               2                 2.666667   \n",
       "4                         0.0              10               627.500000   \n",
       "...                       ...             ...                      ...   \n",
       "12325                     0.0              53              1783.791667   \n",
       "12326                     0.0               5               465.750000   \n",
       "12327                     0.0               6               184.250000   \n",
       "12328                     0.0              15               346.000000   \n",
       "12329                     0.0               3                21.250000   \n",
       "\n",
       "       BounceRates  ExitRates  PageValues  SpecialDay  OperatingSystems  \\\n",
       "0         0.200000   0.200000    0.000000         0.0                 1   \n",
       "1         0.000000   0.100000    0.000000         0.0                 2   \n",
       "2         0.200000   0.200000    0.000000         0.0                 4   \n",
       "3         0.050000   0.140000    0.000000         0.0                 3   \n",
       "4         0.020000   0.050000    0.000000         0.0                 3   \n",
       "...            ...        ...         ...         ...               ...   \n",
       "12325     0.007143   0.029031   12.241717         0.0                 4   \n",
       "12326     0.000000   0.021333    0.000000         0.0                 3   \n",
       "12327     0.083333   0.086667    0.000000         0.0                 3   \n",
       "12328     0.000000   0.021053    0.000000         0.0                 2   \n",
       "12329     0.000000   0.066667    0.000000         0.0                 3   \n",
       "\n",
       "       Browser  Region  TrafficType  Weekend  \n",
       "0            1       1            1        0  \n",
       "1            2       1            2        0  \n",
       "2            1       9            3        0  \n",
       "3            2       2            4        0  \n",
       "4            3       1            4        1  \n",
       "...        ...     ...          ...      ...  \n",
       "12325        6       1            1        1  \n",
       "12326        2       1            8        1  \n",
       "12327        2       1           13        1  \n",
       "12328        2       3           11        0  \n",
       "12329        2       1            2        1  \n",
       "\n",
       "[12330 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 18 19 16 17 20]\n"
     ]
    }
   ],
   "source": [
    "print(X['TrafficType'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to float types (avoids issues down the line)\n",
    "X = np.asarray(X).astype(np.float32)\n",
    "y = np.asarray(y).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Pre-process data prior to running model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y , \n",
    "                                   random_state=104,  \n",
    "                                   test_size=0.25,  \n",
    "                                   shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first step is to produce a \"scaler\" function\n",
    "scaler_train = preprocessing.StandardScaler().fit(X_train)\n",
    "scaler_test  = preprocessing.StandardScaler().fit(X_test)\n",
    "\n",
    "# Apply scaler function\n",
    "X_train_scale = scaler_train.transform(X_train)\n",
    "X_test_scale  = scaler_test.fit(X_test).transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> III. Training a neural network </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Define number of features in $X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(k_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "To define a neural network we start with a configuration setup\n",
    "\n",
    "- We start with an empty canvas with \"Keras\"\n",
    "- Then we successively add how many layers we want <br>\n",
    "and what type\n",
    "\n",
    "For more information about Keras layers:\n",
    "\n",
    "https://www.educative.io/answers/what-are-keras-layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"basic_model\" for now only starts with a configuration\n",
    "\n",
    "basic_model = keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gracebarringer/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# We add how many layers we want, starting with the input layer and \n",
    "# ending with the output layer\n",
    "\n",
    "# This has a dense layer for inputs with \"k\" features\n",
    "basic_model.add(Dense(units=16, activation='relu', input_shape=(k_features,)))\n",
    "\n",
    "# This is the output layer. The sigmoid defines predictions in (0,1)\n",
    "# We choose 1 unit since there is a scalar output (binary classification)\n",
    "\n",
    "basic_model.add(Dense(units = 1, activation='sigmoid'))\n",
    "\n",
    "# Note: If you are using the neural network to predict continuous outcomes,\n",
    "# you may want a different activation function in the output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Define an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam is a type of optimization algorithm\n",
    "\n",
    "adam = keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function to optimize\n",
    "\n",
    "basic_model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Estimate model\n",
    "\n",
    "- The optimization algorithm proceeds sequentially, through epocs\n",
    "- Set a random seed to ensure reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 304us/step - accuracy: 0.7400 - loss: 28.3785 \n",
      "Epoch 2/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282us/step - accuracy: 0.8580 - loss: 0.7375\n",
      "Epoch 3/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step - accuracy: 0.8705 - loss: 0.6557\n",
      "Epoch 4/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step - accuracy: 0.8662 - loss: 0.6398\n",
      "Epoch 5/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step - accuracy: 0.8653 - loss: 0.6179\n",
      "Epoch 6/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step - accuracy: 0.8708 - loss: 0.5884\n",
      "Epoch 7/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step - accuracy: 0.8718 - loss: 0.5255\n",
      "Epoch 8/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step - accuracy: 0.8634 - loss: 0.6275\n",
      "Epoch 9/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step - accuracy: 0.8644 - loss: 0.6778\n",
      "Epoch 10/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step - accuracy: 0.8663 - loss: 0.6004\n",
      "Epoch 11/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280us/step - accuracy: 0.8666 - loss: 0.5897\n",
      "Epoch 12/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - accuracy: 0.8729 - loss: 0.5882\n",
      "Epoch 13/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286us/step - accuracy: 0.8656 - loss: 0.5859\n",
      "Epoch 14/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step - accuracy: 0.8653 - loss: 0.5749\n",
      "Epoch 15/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291us/step - accuracy: 0.8645 - loss: 0.5843\n",
      "Epoch 16/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step - accuracy: 0.8638 - loss: 0.5839\n",
      "Epoch 17/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291us/step - accuracy: 0.8628 - loss: 0.6900\n",
      "Epoch 18/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step - accuracy: 0.8693 - loss: 0.5199\n",
      "Epoch 19/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step - accuracy: 0.8640 - loss: 0.5856\n",
      "Epoch 20/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step - accuracy: 0.8675 - loss: 0.6186\n",
      "Epoch 21/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.8719 - loss: 0.5014\n",
      "Epoch 22/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step - accuracy: 0.8641 - loss: 0.6730\n",
      "Epoch 23/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282us/step - accuracy: 0.8658 - loss: 0.6193\n",
      "Epoch 24/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step - accuracy: 0.8628 - loss: 0.6572\n",
      "Epoch 25/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step - accuracy: 0.8664 - loss: 0.4998\n",
      "Epoch 26/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277us/step - accuracy: 0.8693 - loss: 0.5495\n",
      "Epoch 27/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286us/step - accuracy: 0.8646 - loss: 0.5298\n",
      "Epoch 28/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step - accuracy: 0.8676 - loss: 0.5846\n",
      "Epoch 29/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280us/step - accuracy: 0.8655 - loss: 0.6621\n",
      "Epoch 30/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step - accuracy: 0.8686 - loss: 0.6510\n",
      "Epoch 31/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step - accuracy: 0.8699 - loss: 0.5781\n",
      "Epoch 32/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282us/step - accuracy: 0.8616 - loss: 0.6184\n",
      "Epoch 33/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step - accuracy: 0.8660 - loss: 0.6458\n",
      "Epoch 34/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286us/step - accuracy: 0.8682 - loss: 0.6116\n",
      "Epoch 35/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step - accuracy: 0.8707 - loss: 0.6366\n",
      "Epoch 36/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step - accuracy: 0.8678 - loss: 0.6436\n",
      "Epoch 37/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - accuracy: 0.8672 - loss: 0.6383\n",
      "Epoch 38/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step - accuracy: 0.8665 - loss: 0.6544\n",
      "Epoch 39/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.8744 - loss: 0.5140\n",
      "Epoch 40/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.8719 - loss: 0.5403\n",
      "Epoch 41/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.8617 - loss: 0.6377\n",
      "Epoch 42/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.8737 - loss: 0.5115\n",
      "Epoch 43/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step - accuracy: 0.8713 - loss: 0.5240\n",
      "Epoch 44/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286us/step - accuracy: 0.8701 - loss: 0.6465\n",
      "Epoch 45/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.8712 - loss: 0.6084\n",
      "Epoch 46/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.8681 - loss: 0.6395\n",
      "Epoch 47/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291us/step - accuracy: 0.8684 - loss: 0.5786\n",
      "Epoch 48/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282us/step - accuracy: 0.8675 - loss: 0.6110\n",
      "Epoch 49/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step - accuracy: 0.8703 - loss: 0.5919\n",
      "Epoch 50/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282us/step - accuracy: 0.8716 - loss: 0.5079\n",
      "Epoch 51/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.8666 - loss: 0.5885\n",
      "Epoch 52/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.8705 - loss: 0.5614\n",
      "Epoch 53/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289us/step - accuracy: 0.8670 - loss: 0.6261\n",
      "Epoch 54/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.8696 - loss: 0.6236\n",
      "Epoch 55/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286us/step - accuracy: 0.8671 - loss: 0.4730\n",
      "Epoch 56/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.8673 - loss: 0.6628\n",
      "Epoch 57/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step - accuracy: 0.8714 - loss: 0.5010\n",
      "Epoch 58/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.8709 - loss: 0.4677\n",
      "Epoch 59/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step - accuracy: 0.8712 - loss: 0.5008\n",
      "Epoch 60/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282us/step - accuracy: 0.8719 - loss: 0.5298\n",
      "Epoch 61/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step - accuracy: 0.8692 - loss: 0.5751\n",
      "Epoch 62/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step - accuracy: 0.8703 - loss: 0.6074\n",
      "Epoch 63/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286us/step - accuracy: 0.8684 - loss: 0.6416\n",
      "Epoch 64/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.8744 - loss: 0.4687\n",
      "Epoch 65/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8743 - loss: 0.5355\n",
      "Epoch 66/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265us/step - accuracy: 0.8702 - loss: 0.6044\n",
      "Epoch 67/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289us/step - accuracy: 0.8781 - loss: 0.5141\n",
      "Epoch 68/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.8762 - loss: 0.4865\n",
      "Epoch 69/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.8760 - loss: 0.5096\n",
      "Epoch 70/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.8768 - loss: 0.5111\n",
      "Epoch 71/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266us/step - accuracy: 0.8764 - loss: 0.4804\n",
      "Epoch 72/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283us/step - accuracy: 0.8756 - loss: 0.4939\n",
      "Epoch 73/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280us/step - accuracy: 0.8727 - loss: 0.5223\n",
      "Epoch 74/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.8747 - loss: 0.4500\n",
      "Epoch 75/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291us/step - accuracy: 0.8770 - loss: 0.4733\n",
      "Epoch 76/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.8768 - loss: 0.4974\n",
      "Epoch 77/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step - accuracy: 0.8759 - loss: 0.4948\n",
      "Epoch 78/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step - accuracy: 0.8742 - loss: 0.5225\n",
      "Epoch 79/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.8727 - loss: 0.5104\n",
      "Epoch 80/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.8786 - loss: 0.4831\n",
      "Epoch 81/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283us/step - accuracy: 0.8759 - loss: 0.4908\n",
      "Epoch 82/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step - accuracy: 0.8759 - loss: 0.4838\n",
      "Epoch 83/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286us/step - accuracy: 0.8742 - loss: 0.5496\n",
      "Epoch 84/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step - accuracy: 0.8725 - loss: 0.6451\n",
      "Epoch 85/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291us/step - accuracy: 0.8782 - loss: 0.4721\n",
      "Epoch 86/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step - accuracy: 0.8728 - loss: 0.5117\n",
      "Epoch 87/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - accuracy: 0.8777 - loss: 0.4795\n",
      "Epoch 88/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.8778 - loss: 0.4584\n",
      "Epoch 89/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.8780 - loss: 0.4947\n",
      "Epoch 90/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.8759 - loss: 0.4938\n",
      "Epoch 91/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - accuracy: 0.8755 - loss: 0.5052\n",
      "Epoch 92/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step - accuracy: 0.8753 - loss: 0.4932\n",
      "Epoch 93/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.8743 - loss: 0.4487\n",
      "Epoch 94/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.8746 - loss: 0.5059\n",
      "Epoch 95/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step - accuracy: 0.8780 - loss: 0.4971\n",
      "Epoch 96/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276us/step - accuracy: 0.8757 - loss: 0.5450\n",
      "Epoch 97/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step - accuracy: 0.8769 - loss: 0.4567\n",
      "Epoch 98/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step - accuracy: 0.8731 - loss: 0.4979\n",
      "Epoch 99/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278us/step - accuracy: 0.8733 - loss: 0.6194\n",
      "Epoch 100/100\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273us/step - accuracy: 0.8773 - loss: 0.4901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1488b8f20>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.keras.utils.set_random_seed(0)  \n",
    "\n",
    "# Train model\n",
    "basic_model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> IV. Evaluate a neural network </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Obtain predicted probabilities and convert them to {0,1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/97 [..............................] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 0s 636us/step\n"
     ]
    }
   ],
   "source": [
    "# Convert to array\n",
    "predicted_prob = basic_model.predict(X_test)\n",
    "predicted_prob = tf.squeeze(predicted_prob)\n",
    "\n",
    "# Convert to {0,1} predictions using a 0.5 threshold\n",
    "threshold = 0.5\n",
    "predicted = np.array([1 if x >= threshold else 0 for x in predicted_prob])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Obtain confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fc66228e9a0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtain confusion matrix\n",
    "cm = confusion_matrix(y_test, predicted)\n",
    "\n",
    "displ = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "displ.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "At the moment we defined a very simple neural network <br>\n",
    "with just an input layer and an output layer. <br>\n",
    "\n",
    "Try it yourself!\n",
    "\n",
    "- Increase the number of units in the input layer\n",
    "- Does prediction accuracy improve?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your own code\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "\n",
    "Try it yourself!\n",
    "\n",
    "- Add one or more hidden layers\n",
    "- Does prediction accuracy improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your own code\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Try it yourself!\n",
    "\n",
    "- Import the Mashable dataset that we used earlier <br>\n",
    "(you can find this in this in the ```ArticlesTrain.csv``` and <br>\n",
    "```ArticlesTest.csv``` files in the ```data_raw``` folder)\n",
    "\n",
    "- Try to set up a neural network with a simple input-output layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your own code\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> V. Additional resources </span>\n",
    "\n",
    "<font size = \"5\">\n",
    "\n",
    "Quick guide:\n",
    "\n",
    "https://www.tensorflow.org/tutorials/quickstart/beginner\n",
    "\n",
    "Binary classification:\n",
    "\n",
    "https://www.freecodecamp.org/news/binary-classification-made-simple-with-tensorflow/\n",
    "\n",
    "Image classification:\n",
    "\n",
    "https://www.tensorflow.org/tutorials/images/classification\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45fc1f684f6f416f40889115beff3ddf69879b64cf4bfee48cb72a61e9d15d1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
